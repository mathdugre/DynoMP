\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage[normalem]{ulem}
\usepackage{colortbl}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=black,
    urlcolor=blue
}
\usepackage{subcaption}
\captionsetup[subfigure]{singlelinecheck=false, skip=0pt}

% Remove later
\usepackage{color,soul}
\newcommand{\TG}[1]{\color{blue}\textsc{From Tristan: }#1\color{black}}
\newcommand{\MD}[1]{\color{magenta}\textsc{From Mathieu: }#1\color{black}}
\newcommand{\HL}[1]{\hl{#1}}
% End of remove

\title{DynoMP: A Dynamic Mixed Precision Model for Gradient-Based Optimization}
\author{Mathieu Dugr\'e, Yohan Chatelain, Tristan Glatard}

\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}
\label{sec:introduction}
\MD{Depending on the scope of the paper, we might want to be more broad the MRI pipelines; i.e. MP as a whole.}
Registration is a fundamental step in magnetic resonance imaging (MRI) analysis, essential for comparing images across different subjects, time points, or contrasts. This process is computationally and memory-intensive; prior research~\cite{Dugre2025-fs} has demonstrated that a few functions constitute the primary bottleneck for both runtime and memory usage. Accelerating registration would enable researchers to analyze larger cohorts and significantly reduce the associated resource costs (e.g., CPU, memory, energy, and time).

Mixed precision computing, which strategically combines high- and low-precision arithmetic, offers a promising avenue for pipeline acceleration while maintaining acceptable accuracy. The deep learning community has successfully adopted mixed precision (AMP), leading to its robust implementation in frameworks like PyTorch~\cite{Paszke2019-vk} and TensorFlow~\cite{Abadi2016-vm}. However, its potential remains largely unexplored in other domains. Current methods for applying mixed precision to general pipelines face significant challenges: static analysis is often impractical for large or complex codebases, and methods requiring multiple pipeline executions are inefficient when processing heterogeneous data and dealing with compute-intensive workflows.

Another approach to accelerate pipelines is leveraging GPUs. For instance, FireANTs~\cite{TODO}, a GPU port of the widely used Advanced Normalization Tools (ANTs)~\cite{Avants2020-xx}, achieves comparable registration accuracy while dramatically reducing runtime from several hours to less than a minute. Nevertheless, the high cost and limited availability of GPUs often restrict their widespread use in academic settings.

\MD{TODO: revise}
More recently, several deep learning (DL) models~\cite{FastSurfer, SynthMorph, SythSeg, Others?} proved successful at accelerating classical MRI processing steps without compromising accuracy. While these pipeline often benefits from faster runtime, further improved by their GPU support, mixed precision arithmetic is still beneficial for performance improvement. Indeed, most modern DL image processing model leverage the AMP feature from PyTorch or TensorFlow.

In this work, we introduce a novel method to dynamically adjust the precision of gradient-based optimization process based on a theoretical model derived from Hayford et al.~\cite{Hayford2024-kb}. We apply our method to both classical and DL pipelines: ANTs Registration~\cite{Avants2020-xx}, ITK Elastix~\cite{TODO}, and FastSurfer~\cite{TODO}. We assess the impact of this dynamic precision adjustment on the output accuracy when compared to the default pipeline precision.


\section{Background}
\label{sec:background}

\subsection{Reduced and Mixed Precision Arithmetic}
% What is reduced precision
% Problem with standard Fp64/FP32
% How does it address this problem
% Why is it useful in the context of scientific applications such as ANTs registration

% Mixed precision: Temporal and Spatial optimization
% More complex to implement, fine tune, and diagnose numerical error
% But even larger speedups

% - Successful implementation in DL: Often store reduced weigth and perform arithmetics on mixed formats
% - Adoption in Deep Learning: PyTorch and TensorFlow
% - Limited to few hardware formats 
% - Classical pipelines don't have an out-of-the-box method for mixed precision, and often rely on FP64 by default

% New hardware format are costly
% Simulation allows for cheap experimentation, but add large overhead and not suited for production
% Need for mixed precision methods to leverage current hardware format
% We focus on current data format rather than proposing new suitable ones.

\subsection{Determining Precision Requirements}

% Static analysis guarantee the precision needed
% Great for toy example, but impractical for large and complex codebase

% Two main categories of dynamic analysis: Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT)
% Post-Training Quantization
% - 
% Quantization-Aware training
% -
% 
% -> These methods generally require multiple execution of the application. While it makes sense in Deep Learning settings were training is done once and inference multiple times, for classical optimization problem the "training" is done for each new data point. Therefore, re-exucuting the application only leads to overhead and provide no benefits.


\section{Method}
\label{sec:method}

\subsection{Pipelines}
\subsubsection{ANTs Registration}
ANTs registration is a multi-stage, multi-resolution optimization process for aligning images, enabling their comparison. The pipeline begins with an initial alignment using the center of mass of the moving image's intensity. Subsequently, it proceeds through three stages---rigid, affine, and symmetric normalization (SyN)~\cite{Avants2008-ea}---each utilizing four multi-resolution levels. By default, the rigid and affine stages use Mutual Information (MI) as the objective function, while SyN uses Cross-Correlation (CC). The optimization iterates until reaching a convergence threshold ($1\times10^{-6}$, by default) over the last 10 iterations or the maximum iteration count. ANTs leverages the registration framework from The Insight Toolkit (ITK)~\cite{McCormick2014-ok,Yoo2002-ve} for computation. Figure~\ref{fig:ants-overview} depicts the overview of the ANTs registration pipeline.
% TODO Fix the layout of the figure
% A | C
% B | C
\begin{figure}[htb!]
	\centering
    \begin{subfigure}[t]{\columnwidth}
		\caption{Multi-stages}
		\includegraphics[width=\columnwidth]{figures/ants-stages.pdf}
	\end{subfigure}
	\begin{subfigure}[t]{\columnwidth}
		\caption{Resolution levels}
		\includegraphics[width=\columnwidth]{figures/ants-multi-resolution.pdf}
	\end{subfigure}
	\begin{subfigure}[t]{\columnwidth}
        \centering
		\caption{ITK optimization process}
		\includegraphics[width=0.8\columnwidth]{figures/ants-optimization.pdf}
	\end{subfigure}
	\caption{\MD{TODO}}
	\label{fig:ants-overview}
\end{figure}

\subsubsection{ITK Elastix}
\MD{TODO}

\subsubsection{FastSurfer}
\MD{TODO}

\subsection{Precision Estimation}
We adapted Hayford et al.~\cite{Hayford2024-kb} theoretical framework on rounding errors to analyze ANTs registration convergence. Their theorem establishes a link between convergence stability, data precision, the Lipschitz constant (K), and parameter norms. We modified the ITK library to probe the gradient norm $\nabla\mathcal{L}(\theta)$, parameter norm $\|\theta\|$, and estimate $K$ via finite differences at each iteration. These metrics are used to compute the theoretical minimum precision ($p_{min}$) required to ensure the gradient signal exceeds the noise inherent to a given data format.

\MD{TODO provide more mathematical details}

\subsection{Dynamic Precision Control}
We leveraged the VPREC backend from Verificarlo~\cite{Denis2015-zf,Chatelain2019-vw} to simulate arithmetic operations at arbitrary virtual precisions. We instrumented and recompiled the ITK and ANTs source code to compute the theoretical minimum required precision ($p_{min}$) at every iteration. These computed values dynamically drive VPREC probes, which we inserted into the optimization loop to restrict the precision at an iteration-wise granularity. To mitigate frequent oscillations in precision, we applied a moving average smoothing (window $N=5$) to the estimated $p_{min}$. Here forth, we use the term dynamic mixed precision (DMP) to describe this method. Figure~\ref{fig:vprec-probe} illustrate the dynamic instrumentation process.
\begin{figure*}[htb!]
	\centering
	\includegraphics[width=\textwidth]{figures/vprec.pdf}
	\caption{}
	\label{fig:vprec-probe}
\end{figure*}

\subsection{Validation Metrics}
We evaluated the accuracy of our dynamic precision model against a baseline FP64 (double precision) version of ANTs by computing the relative difference in registration outputs. We also report the number of precision bits saved by our model compared to the baseline.

\subsection{Dataset \& Preprocessing}
We utilized the \textit{BMB\_1} site from the CoRR dataset~\cite{Zuo2014-ub} to tune and evaluate our method (N=50; age: 30.8 [19.9--59.7]; 52\% F). We processed the anatomical T1-weighted volumes, performing skull-stripping via the \textit{antsBrainExtraction.sh} script. Brain-extracted volumes were visually quality-controlled against the TemplateFlow tpl-MNI152NLin2009cAsym template.

\subsection{Reproducibility}
We recompiled ITK and ANTs for the x86-64 architecture, containerizing the pipeline in Docker and converting it to an Apptainer image for HPC execution. The modified source code and experiment scripts are publicly available:
\begin{itemize}
    \item ITK: https://github.com/mathdugre/ITK
    \item ANTs: https://github.com/mathdugre/ANTs
    \item Experiments: https://github.com/mathdugre/phd-p3
\end{itemize}


\section{Results}
\label{sec:results}
\subsection{Prediction of precision requirements}
Figure~\ref{fig:pmin-std-bounds} illustrates the required precision per iteration, estimated via our theoretical model, and the virtual precision set by the VPREC backend. We report the average across all subjects ($N=50$) with standard deviation bounds. In the SyN stage, our model indicates that FP24 remains sufficient for convergence. Conversely, during rigid and affine stages, FP32 suffices for most iterations at level 0. However, as resolution increases and smoothing decreases, the required precision escalates, eventually exceeding FP32. Across all multi-resolution levels, the predicted requirement always breaches the FP32 threshold, though it occasionally lowers back below it before the registration level finishes.
\begin{figure*}[htb!]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/pmin_std_bounds.png}
    \caption{}
    \label{fig:pmin-std-bounds}
\end{figure*}

\subsection{Limited accuracy loss}
Figure~\ref{fig:rel-diff} displays the relative accuracy difference between our DMP method and the FP64 baseline at the final iteration, where lower values indicate better performance for our method. We report individual subject differences, along with the mean and quantiles. Overall, the mean relative difference stays below $1\times10^{-4}$, with the vast majority of values ($591/600)$ falling below $1\times10^{-3}$. Notably, our DMP model frequently outperforms the baseline ($267/600$), an effect most pronounced in the affine stage at level 0.
\begin{figure*}[htb!]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/rel_diff_fp64_amp.png}
    \caption{}
    \label{fig:rel-diff}
\end{figure*}


\section{Discussion}
\label{sec:discussion}
\subsection{Theoretical Assumptions}
The theorem from Hayford et al.~\cite{Hayford2024-kb} requires two assumptions: (1) the loss function must be convex, and (2) the gradient of the loss must be K-Lipschitz with $K\le1/\eta$. In practice, verifying these assumptions for complex pipelines is difficult, and for complex optimization problems, the loss convexity assumption is frequently unsatisfied. However, our results demonstrate that we can still leverage this simple model to predict the required minimal precision at each iteration while maintaining acceptable accuracy.

\subsection{Casting Overhead}
To prevent excessive casting overhead caused by oscillating precision requirements between iterations, we utilize a rolling average over a window size of five. A stricter approach would require the precision to increase monotonically with the iteration count at each resolution level. However, if a noisy prediction were to occur early on, it would unnecessarily penalize performance for the remainder of the level. In future efforts, we could compare both approaches, as well as test different window sizes.

\subsection{Mixed Precision in Practice}
Implementing mixed precision in a production environment presents several practical challenges. For example, the current version of the ITK library contains a bug that forces input data to be cast to double precision during interpolation computations. This results in unnecessary overhead, as the system must cast single-precision inputs to double and back during processing. Correcting this is difficult due to the complexity and scale of the existing codebase. Furthermore, extending support to other data formats remains non-trivial. On the hardware side, support for mixed precision is limited on standard CPUs; while specialized hardware exists, the cost is often prohibitive. Finally, the system's robustness is sensitive to data heterogeneity, which can lead to critical failures when input consistency is not maintained.

\subsection{Experimental Constraints (Range Constant at 8 Bits)}
When simulating different data formats with VPREC, we modified only the precision bits and ignored the exponent range to limit the overhead of calculating the correct range. This decision is supported by our previous results~\cite{Dugre2025-fs}, which showed no significant difference in accuracy when varying the exponent range between 7 and 8 for precisions ranging from 7 to 23 bits.

\subsection{Limitations of the FP64 Baseline}
We assess accuracy relative to an FP64 baseline; however, the theoretically optimal precision and output remain unknown. In image registration, there is no absolute ground truth, as multiple valid solutions can exist. Therefore, while FP64 serves as a high-precision reference, it should not be mistaken for a ground truth validation.

\section{Conclusion}
\label{sec:conclusion}
In summary, this work demonstrates that our theoretical model effectively predicts minimal precision requirements for image registration in ANTs, maintaining accuracy even when strict convexity assumptions are relaxed. We employ a rolling average smoothing strategy to mitigate precision oscillation, avoiding the potential performance penalties of a stricter monotonic approach. However, while the potential for computational efficiency is clear, practical application is currently hindered by a casting bug in the ITK library and limited hardware support for diverse data formats. Future adoption will depend on addressing these infrastructural constraints and validating performance on real hardware, rather than relying on virtual precision simulations.

\bibliography{paper.bib}
\bibliographystyle{IEEEtran}
\end{document}
