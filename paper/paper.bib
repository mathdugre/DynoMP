@ARTICLE{Kingma2014-uf,
  title         = "{Adam: A method for stochastic optimization}",
  author        = "Kingma, Diederik P and Ba, Jimmy",
  journal       = "arXiv [cs.LG]",
  abstract      = "We introduce Adam, an algorithm for first-order
                   gradient-based optimization of stochastic objective
                   functions, based on adaptive estimates of lower-order
                   moments. The method is straightforward to implement, is
                   computationally efficient, has little memory requirements, is
                   invariant to diagonal rescaling of the gradients, and is well
                   suited for problems that are large in terms of data and/or
                   parameters. The method is also appropriate for non-stationary
                   objectives and problems with very noisy and/or sparse
                   gradients. The hyper-parameters have intuitive
                   interpretations and typically require little tuning. Some
                   connections to related algorithms, on which Adam was
                   inspired, are discussed. We also analyze the theoretical
                   convergence properties of the algorithm and provide a regret
                   bound on the convergence rate that is comparable to the best
                   known results under the online convex optimization framework.
                   Empirical results demonstrate that Adam works well in
                   practice and compares favorably to other stochastic
                   optimization methods. Finally, we discuss AdaMax, a variant
                   of Adam based on the infinity norm.",
  month         =  dec,
  year          =  2014,
  url           = "http://arxiv.org/abs/1412.6980",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1412.6980"
}

@ARTICLE{Henschel2022-wa,
  title     = "{FastSurferVINN: Building resolution-independence into deep
               learning segmentation methods-A solution for HighRes brain {MRI}}",
  author    = "Henschel, Leonie and K{\"{u}}gler, David and Reuter, Martin",
  journal   = "NeuroImage",
  publisher = "Elsevier BV",
  volume    =  251,
  number    =  118933,
  pages     =  118933,
  abstract  = "Leading neuroimaging studies have pushed 3T MRI acquisition
               resolutions below 1.0 mm for improved structure definition and
               morphometry. Yet, only few, time-intensive automated image
               analysis pipelines have been validated for high-resolution
               (HiRes) settings. Efficient deep learning approaches, on the
               other hand, rarely support more than one fixed resolution
               (usually 1.0 mm). Furthermore, the lack of a standard
               submillimeter resolution as well as limited availability of
               diverse HiRes data with sufficient coverage of scanner, age,
               diseases, or genetic variance poses additional, unsolved
               challenges for training HiRes networks. Incorporating
               resolution-independence into deep learning-based segmentation,
               i.e., the ability to segment images at their native resolution
               across a range of different voxel sizes, promises to overcome
               these challenges, yet no such approach currently exists. We now
               fill this gap by introducing a Voxel-size Independent Neural
               Network (VINN) for resolution-independent segmentation tasks and
               present FastSurferVINN, which (i) establishes and implements
               resolution-independence for deep learning as the first method
               simultaneously supporting 0.7-1.0 mm whole brain segmentation,
               (ii) significantly outperforms state-of-the-art methods across
               resolutions, and (iii) mitigates the data imbalance problem
               present in HiRes datasets. Overall, internal
               resolution-independence mutually benefits both HiRes and 1.0 mm
               MRI segmentation. With our rigorously validated FastSurferVINN we
               distribute a rapid tool for morphometric neuroimage analysis. The
               VINN architecture, furthermore, represents an efficient
               resolution-independent segmentation method for wider application.",
  month     =  may,
  year      =  2022,
  url       = "https://www.sciencedirect.com/science/article/pii/S1053811922000623",
  keywords  = "Artificial intelligence; Computational neuroimaging; Deep
               learning; High-resolution; Structural MRI",
  doi       = "10.1016/j.neuroimage.2022.118933",
  pmc       = "PMC9801435",
  pmid      =  35122967,
  issn      = "1053-8119,1095-9572",
  language  = "en"
}

@ARTICLE{Hoffmann2022-hu,
  title    = "{SynthMorph: Learning Contrast-Invariant Registration Without
              Acquired Images}",
  author   = "Hoffmann, Malte and Billot, Benjamin and Greve, Douglas N and
              Iglesias, Juan Eugenio and Fischl, Bruce and Dalca, Adrian V",
  journal  = "IEEE transactions on medical imaging",
  volume   =  41,
  number   =  3,
  pages    = "543--558",
  abstract = "We introduce a strategy for learning image registration without
              acquired imaging data, producing powerful networks agnostic to
              contrast introduced by magnetic resonance imaging (MRI). While
              classical registration methods accurately estimate the spatial
              correspondence between images, they solve an optimization problem
              for every new image pair. Learning-based techniques are fast at
              test time but limited to registering images with contrasts and
              geometric content similar to those seen during training. We
              propose to remove this dependency on training data by leveraging a
              generative strategy for diverse synthetic label maps and images
              that exposes networks to a wide range of variability, forcing them
              to learn more invariant features. This approach results in
              powerful networks that accurately generalize to a broad array of
              MRI contrasts. We present extensive experiments with a focus on 3D
              neuroimaging, showing that this strategy enables robust and
              accurate registration of arbitrary MRI contrasts even if the
              target contrast is not seen by the networks during training. We
              demonstrate registration accuracy surpassing the state of the art
              both within and across contrasts, using a single model.
              Critically, training on arbitrary shapes synthesized from noise
              distributions results in competitive performance, removing the
              dependency on acquired data of any kind. Additionally, since
              anatomical label maps are often available for the anatomy of
              interest, we show that synthesizing images from these dramatically
              boosts performance, while still avoiding the need for real
              intensity images. Our code is available at doic
              https://w3id.org/synthmorph.",
  month    =  mar,
  year     =  2022,
  url      = "http://dx.doi.org/10.1109/TMI.2021.3116879",
  doi      = "10.1109/TMI.2021.3116879",
  pmc      = "PMC8891043",
  pmid     =  34587005,
  issn     = "0278-0062,1558-254X",
  language = "en"
}

@ARTICLE{Billot2023-vp,
  title    = "{SynthSeg: Segmentation of brain MRI scans of any contrast and
              resolution without retraining}",
  author   = "Billot, Benjamin and Greve, Douglas N and Puonti, Oula and
              Thielscher, Axel and Van Leemput, Koen and Fischl, Bruce and
              Dalca, Adrian V and Iglesias, Juan Eugenio and {ADNI}",
  journal  = "Medical image analysis",
  volume   =  86,
  pages    =  102789,
  abstract = "Despite advances in data augmentation and transfer learning,
              convolutional neural networks (CNNs) difficultly generalise to
              unseen domains. When segmenting brain scans, CNNs are highly
              sensitive to changes in resolution and contrast: even within the
              same MRI modality, performance can decrease across datasets. Here
              we introduce SynthSeg, the first segmentation CNN robust against
              changes in contrast and resolution. SynthSeg is trained with
              synthetic data sampled from a generative model conditioned on
              segmentations. Crucially, we adopt a domain randomisation strategy
              where we fully randomise the contrast and resolution of the
              synthetic training data. Consequently, SynthSeg can segment real
              scans from a wide range of target domains without retraining or
              fine-tuning, which enables straightforward analysis of huge
              amounts of heterogeneous clinical data. Because SynthSeg only
              requires segmentations to be trained (no images), it can learn
              from labels obtained by automated methods on diverse populations
              (e.g., ageing and diseased), thus achieving robustness to a wide
              range of morphological variability. We demonstrate SynthSeg on
              5,000 scans of six modalities (including CT) and ten resolutions,
              where it exhibits unparallelled generalisation compared with
              supervised CNNs, state-of-the-art domain adaptation, and Bayesian
              segmentation. Finally, we demonstrate the generalisability of
              SynthSeg by applying it to cardiac MRI and CT scans.",
  month    =  may,
  year     =  2023,
  url      = "http://dx.doi.org/10.1016/j.media.2023.102789",
  keywords = "CNN; Contrast and resolution invariance; Domain randomisation;
              Segmentation",
  doi      = "10.1016/j.media.2023.102789",
  pmc      = "PMC10154424",
  pmid     =  36857946,
  issn     = "1361-8415,1361-8423",
  language = "en"
}

@ARTICLE{Yoo2002-ve,
  title    = "{Engineering and algorithm design for an image processing Api: a
              technical report on ITK--the Insight Toolkit}",
  author   = "Yoo, Terry S and Ackerman, Michael J and Lorensen, William E and
              Schroeder, Will and Chalana, Vikram and Aylward, Stephen and
              Metaxas, Dimitris and Whitaker, Ross",
  journal  = "Studies in health technology and informatics",
  volume   =  85,
  pages    = "586--592",
  abstract = "We present the detailed planning and execution of the Insight
              Toolkit (ITK), an application programmers interface (API) for the
              segmentation and registration of medical image data. This public
              resource has been developed through the NLM Visible Human Project,
              and is in beta test as an open-source software offering under
              cost-free licensing. The toolkit concentrates on 3D medical data
              segmentation and registration algorithms, multimodal and
              multiresolution capabilities, and portable platform independent
              support for Windows, Linux/Unix systems. This toolkit was built
              using current practices in software engineering. Specifically, we
              embraced the concept of generic programming during the development
              of these tools, working extensively with C++ templates and the
              freedom and flexibility they allow. Software development tools for
              distributed consortium-based code development have been created
              and are also publicly available. We discuss our assumptions,
              design decisions, and some lessons learned.",
  year     =  2002,
  url      = "https://www.ncbi.nlm.nih.gov/pubmed/15458157",
  pmid     =  15458157,
  issn     = "0926-9630",
  language = "en"
}

@ARTICLE{Avants2008-ea,
  title    = "{Symmetric diffeomorphic image registration with
              cross-correlation: evaluating automated labeling of elderly and
              neurodegenerative brain}",
  author   = "Avants, B B and Epstein, C L and Grossman, M and Gee, J C",
  journal  = "Medical image analysis",
  volume   =  12,
  number   =  1,
  pages    = "26--41",
  abstract = "One of the most challenging problems in modern neuroimaging is
              detailed characterization of neurodegeneration. Quantifying
              spatial and longitudinal atrophy patterns is an important
              component of this process. These spatiotemporal signals will aid
              in discriminating between related diseases, such as frontotemporal
              dementia (FTD) and Alzheimer's disease (AD), which manifest
              themselves in the same at-risk population. Here, we develop a
              novel symmetric image normalization method (SyN) for maximizing
              the cross-correlation within the space of diffeomorphic maps and
              provide the Euler-Lagrange equations necessary for this
              optimization. We then turn to a careful evaluation of our method.
              Our evaluation uses gold standard, human cortical segmentation to
              contrast SyN's performance with a related elastic method and with
              the standard ITK implementation of Thirion's Demons algorithm. The
              new method compares favorably with both approaches, in particular
              when the distance between the template brain and the target brain
              is large. We then report the correlation of volumes gained by
              algorithmic cortical labelings of FTD and control subjects with
              those gained by the manual rater. This comparison shows that, of
              the three methods tested, SyN's volume measurements are the most
              strongly correlated with volume measurements gained by expert
              labeling. This study indicates that SyN, with cross-correlation,
              is a reliable method for normalizing and making anatomical
              measurements in volumetric MRI of patients and at-risk elderly
              individuals.",
  month    =  feb,
  year     =  2008,
  url      = "http://dx.doi.org/10.1016/j.media.2007.06.004",
  doi      = "10.1016/j.media.2007.06.004",
  pmc      = "PMC2276735",
  pmid     =  17659998,
  issn     = "1361-8415,1361-8423",
  language = "en"
}

@ARTICLE{Isola2016-lu,
  title         = "{Image-to-image translation with conditional adversarial
                   networks}",
  author        = "Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros,
                   Alexei A",
  journal       = "arXiv [cs.CV]",
  abstract      = "We investigate conditional adversarial networks as a
                   general-purpose solution to image-to-image translation
                   problems. These networks not only learn the mapping from
                   input image to output image, but also learn a loss function
                   to train this mapping. This makes it possible to apply the
                   same generic approach to problems that traditionally would
                   require very different loss formulations. We demonstrate that
                   this approach is effective at synthesizing photos from label
                   maps, reconstructing objects from edge maps, and colorizing
                   images, among other tasks. Indeed, since the release of the
                   pix2pix software associated with this paper, a large number
                   of internet users (many of them artists) have posted their
                   own experiments with our system, further demonstrating its
                   wide applicability and ease of adoption without the need for
                   parameter tweaking. As a community, we no longer
                   hand-engineer our mapping functions, and this work suggests
                   we can achieve reasonable results without hand-engineering
                   our loss functions either.",
  month         =  nov,
  year          =  2016,
  url           = "http://arxiv.org/abs/1611.07004",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "1611.07004",
  doi           = "10.48550/arXiv.1611.07004"
}

@ARTICLE{Dugre2025-fs,
  title    = "{An analysis of performance bottlenecks in MRI preprocessing}",
  author   = "Dugr\'{e}, Mathieu and Chatelain, Yohan and Glatard, Tristan",
  journal  = "GigaScience",
  volume   =  24,
  pages    = "giae098",
  abstract = "Magnetic Resonance Image (MRI) pre-processing is a critical step
              for neuroimaging analysis. However, the computational cost of MRI
              pre-processing pipelines is a major bottleneck for large cohort
              studies and some clinical applications. While High-Performance
              Computing (HPC) and, more recently, Deep Learning have been
              adopted to accelerate the computations, these techniques require
              costly hardware and are not accessible to all researchers.
              Therefore, it is important to understand the performance
              bottlenecks of MRI pre-processing pipelines to improve their
              performance. Using Intel VTune profiler, we characterized the
              bottlenecks of several commonly used MRI-preprocessing pipelines
              from the ANTs, FSL, and FreeSurfer toolboxes. We found that few
              functions contributed to most of the CPU time, and that linear
              interpolation was the largest contributor. Data access was also a
              substantial bottleneck. We identified a bug in the ITK library
              that impacts the performance of ANTs pipeline in single-precision
              and a potential issue with the OpenMP scaling in FreeSurfer
              recon-all. Our results provide a reference for future efforts to
              optimize MRI pre-processing pipelines.",
  month    =  mar,
  year     =  2025,
  url      = "http://dx.doi.org/10.1093/gigascience/giae098",
  doi      = "10.1093/gigascience/giae098"
}

@ARTICLE{Avants2020-xx,
  title     = "{Advanced normalization tools (ANTs)}",
  author    = "Avants, B and Tustison, N and Johnson, Hans J",
  journal   = "The insight journal",
  publisher = "psychiatry.ucsd.edu",
  abstract  = "... This update to ANTs documentation was initiated April 29,
               2014. This document does not cover all of ANTs functionality --
               but summarizes the most frequently used components ...",
  month     =  dec,
  year      =  2020,
  url       = "https://psychiatry.ucsd.edu/research/programs-centers/snl/_files/ants2.pdf",
  doi       = "10.5281/ZENODO.5138159"
}

@ARTICLE{Paszke2019-vk,
  title     = "{PyTorch: An imperative style, high-performance deep learning
               library}",
  author    = "Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam
               and Bradbury, James and Chanan, Gregory and Killeen, Trevor and
               Lin, Zeming and Gimelshein, N and Antiga, L and Desmaison, Alban
               and K{\"{o}}pf, Andreas and Yang, E and DeVito, Zach and Raison,
               Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner,
               Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith",
  journal   = "Advances in neural information processing systems",
  publisher = "proceedings.neurips.cc",
  volume    = "abs/1912.01703",
  abstract  = "Deep learning frameworks have often focused on either usability
               or speed, but not both. PyTorch is a machine learning library
               that shows that these two goals are in fact compatible: it was
               designed from first principles to support an imperative and
               Pythonic programming style that supports code as a model, makes
               debugging easy and is consistent with other popular scientific
               computing libraries, while remaining efficient and supporting
               hardware accelerators such as GPUs. In this paper, we detail the
               principles that drove the implementation of PyTorch and how they
               are reflected in its architecture. We emphasize that every aspect
               of PyTorch is a regular Python program under the full control of
               its user. We also explain how the careful and pragmatic
               implementation of the key components of its runtime enables them
               to work together to achieve compelling performance. We
               demonstrate the efficiency of individual subsystems, as well as
               the overall speed of PyTorch on several commonly used benchmarks.",
  month     =  dec,
  year      =  2019,
  url       = "https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html",
  eprint    = "1912.01703",
  issn      = "1049-5258"
}

@ARTICLE{Abadi2016-vm,
  title     = "{TensorFlow: Large-scale machine learning on heterogeneous
               distributed systems}",
  author    = "Abadi, Mart\'{\i}n and Agarwal, Ashish and Barham, P and Brevdo,
               E and Chen, Z and Citro, C and Corrado, G and Davis, Andy and
               Dean, J and Devin, M and Ghemawat, Sanjay and Goodfellow, I and
               Harp, A and Irving, G and Isard, M and Jia, Yangqing and
               J\'{o}zefowicz, R and Kaiser, Lukasz and Kudlur, M and Levenberg,
               J and Man\'{e}, Dandelion and Monga, R and Moore, Sherry and
               Murray, D and Olah, C and Schuster, M and Shlens, Jonathon and
               Steiner, Benoit and Sutskever, I and Talwar, Kunal and Tucker, P
               and Vanhoucke, Vincent and Vasudevan, Vijay and Vi\'{e}gas, F and
               Vinyals, O and Warden, Pete and Wattenberg, M and Wicke, M and
               Yu, Yuan and Zheng, Xiaoqiang",
  journal   = "ArXiv",
  publisher = "Mountain View, CA: Tensorflow",
  volume    = "abs/1603.04467",
  abstract  = "TensorFlow is an interface for expressing machine learning
               algorithms, and an implementation for executing such algorithms.
               A computation expressed using TensorFlow can be executed with
               little or no change on a wide variety of heterogeneous systems,
               ranging from mobile devices such as phones and tablets up to
               large-scale distributed systems of hundreds of machines and
               thousands of computational devices such as GPU cards. The system
               is flexible and can be used to express a wide variety of
               algorithms, including training and inference algorithms for deep
               neural network models, and it has been used for conducting
               research and for deploying machine learning systems into
               production across more than a dozen areas of computer science and
               other fields, including speech recognition, computer vision,
               robotics, information retrieval, natural language processing,
               geographic information extraction, and computational drug
               discovery. This paper describes the TensorFlow interface and an
               implementation of that interface that we have built at Google.
               The TensorFlow API and a reference implementation were released
               as an open-source package under the Apache 2.0 license in
               November, 2015 and are available at www.tensorflow.org.",
  month     =  mar,
  year      =  2016,
  url       = "http://arxiv.org/abs/1603.04467",
  eprint    = "1603.04467",
  issn      = "2331-8422"
}

@MISC{Wang2019-qe,
  title        = "{BFloat16: The secret to high performance on Cloud {TPUs}}",
  author       = "Wang, Shibo and Kanwar, Pankaj",
  booktitle    = "{Google Cloud Blog}",
  publisher    = "Google Cloud",
  abstract     = "How the high performance of Google Cloud TPUs is driven by
                  Brain Floating Point Format, or bfloat16",
  month        =  aug,
  year         =  2019,
  howpublished = "\url{https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus}",
  note         = "Accessed: 2024-5-3",
  language     = "en"
}

@INPROCEEDINGS{Chatelain2019-vw,
  title     = "{Automatic Exploration of Reduced Floating-Point Representations
               in Iterative Methods}",
  author    = "Chatelain, Yohan and Petit, Eric and de Oliveira Castro, Pablo
               and Lartigue, Ghislain and Defour, David",
  booktitle = "{Euro-Par 2019: Parallel Processing}",
  publisher = "Springer International Publishing",
  pages     = "481--494",
  abstract  = "With the ever-increasing need for computation of scientific
               applications, new application domains, and major energy
               constraints, the landscape of floating-point computation is
               changing. New floating-point representation formats are emerging
               and there is a need for tools to simulate their impact in legacy
               codes. In this paper, we propose an automatic tool to evaluate
               the effect of adapting the floating point precision for each
               operation over time, which is particularly useful in iterative
               schemes. We present a backend to emulate any IEEE-754
               floating-point operation in lower precision. We tested the
               numerical errors resilience of our solutions thanks to Monte
               Carlo Arithmetic and demonstrated the effectiveness of this
               methodology on YALES2, a large Combustion-CFD HPC code, by
               achieving 28\% to 67\% reduction in communication volume by
               lowering precision.",
  year      =  2019,
  url       = "http://dx.doi.org/10.1007/978-3-030-29400-7_34",
  doi       = "10.1007/978-3-030-29400-7\_34"
}

@ARTICLE{Denis2015-zf,
  title         = "{Verificarlo: checking floating point accuracy through Monte
                   Carlo Arithmetic}",
  author        = "Denis, Christophe and De Oliveira Castro, Pablo and Petit,
                   Eric",
  journal       = "arXiv [cs.MS]",
  abstract      = "Numerical accuracy of floating point computation is a well
                   studied topic which has not made its way to the end-user in
                   scientific computing. Yet, it has become a critical issue
                   with the recent requirements for code modernization to
                   harness new highly parallel hardware and perform higher
                   resolution computation. To democratize numerical accuracy
                   analysis, it is important to propose tools and methodologies
                   to study large use cases in a reliable and automatic way. In
                   this paper, we propose verificarlo, an extension to the LLVM
                   compiler to automatically use Monte Carlo Arithmetic in a
                   transparent way for the end-user. It supports all the major
                   languages including C, C++, and Fortran. Unlike
                   source-to-source approaches, our implementation captures the
                   influence of compiler optimizations on the numerical
                   accuracy. We illustrate how Monte Carlo Arithmetic using the
                   verificarlo tool outperforms the existing approaches on
                   various use cases and is a step toward automatic numerical
                   analysis.",
  month         =  sep,
  year          =  2015,
  url           = "http://arxiv.org/abs/1509.01347",
  archivePrefix = "arXiv",
  primaryClass  = "cs.MS",
  eprint        = "1509.01347"
}

@INCOLLECTION{Zhu2022-uw,
  title     = "{Swin-VoxelMorph: A symmetric unsupervised learning model for
               deformable medical image registration using swin transformer}",
  author    = "Zhu, Yongpei and Lu, Shi",
  booktitle = "{Lecture Notes in Computer Science}",
  publisher = "Springer Nature Switzerland",
  address   = "Cham",
  pages     = "78--87",
  abstract  = "10.1007/978-3-031-16446-0\_8",
  series    = "Lecture notes in computer science",
  year      =  2022,
  url       = "https://doi.org/10.1007/978-3-031-16446-0_8",
  doi       = "10.1007/978-3-031-16446-0\_8",
  isbn      = "9783031164453,9783031164460",
  issn      = "0302-9743,1611-3349",
  language  = "en"
}

@ARTICLE{Balakrishnan2019-rx,
  title     = "{VoxelMorph: A learning framework for deformable medical image
               registration}",
  author    = "Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R and Guttag,
               John and Dalca, Adrian V",
  journal   = "IEEE transactions on medical imaging",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  38,
  number    =  8,
  pages     = "1788--1800",
  abstract  = "We present VoxelMorph, a fast learning-based framework for
               deformable, pairwise medical image registration. Traditional
               registration methods optimize an objective function for each pair
               of images, which can be time-consuming for large datasets or rich
               deformation models. In contrast to this approach, and building on
               recent learning-based methods, we formulate registration as a
               function that maps an input image pair to a deformation field
               that aligns these images. We parameterize the function via a
               convolutional neural network (CNN), and optimize the parameters
               of the neural network on a set of images. Given a new pair of
               scans, VoxelMorph rapidly computes a deformation field by
               directly evaluating the function. In this work, we explore two
               different training strategies. In the first (unsupervised)
               setting, we train the model to maximize standard image matching
               objective functions that are based on the image intensities. In
               the second setting, we leverage auxiliary segmentations available
               in the training data. We demonstrate that the unsupervised
               model's accuracy is comparable to state-of-the-art methods, while
               operating orders of magnitude faster. We also show that
               VoxelMorph trained with auxiliary data improves registration
               accuracy at test time, and evaluate the effect of training set
               size on registration. Our method promises to speed up medical
               image analysis and processing pipelines, while facilitating novel
               directions in learning-based registration and its applications.
               Our code is freely available at
               https://github.com/voxelmorph/voxelmorph.",
  month     =  feb,
  year      =  2019,
  url       = "https://doi.org/10.1109/tmi.2019.2897538",
  doi       = "10.1109/TMI.2019.2897538",
  pmid      =  30716034,
  issn      = "0278-0062,1558-254X",
  language  = "en"
}

@ARTICLE{Hayford2024-kb,
  title     = "{Speeding up and reducing memory usage for scientific machine
               learning via mixed precision}",
  author    = "Hayford, Joel and Goldman-Wetzler, Jacob and Wang, Eric and Lu,
               Lu",
  journal   = "Computer methods in applied mechanics and engineering",
  publisher = "Elsevier BV",
  volume    =  428,
  number    =  117093,
  pages     =  117093,
  month     =  aug,
  year      =  2024,
  url       = "https://www.sciencedirect.com/science/article/pii/S0045782524003499",
  doi       = "10.1016/j.cma.2024.117093",
  issn      = "0045-7825,1879-2138",
  language  = "en"
}

@ARTICLE{Jena2024-ud,
  title         = "{FireANTs: Adaptive Riemannian Optimization for Multi-Scale
                   Diffeomorphic Matching}",
  author        = "Jena, Rohit and Chaudhari, Pratik and Gee, James C",
  journal       = "arXiv [cs.CV]",
  abstract      = "The paper proposes FireANTs, the first multi-scale Adaptive
                   Riemannian Optimization algorithm for dense diffeomorphic
                   image matching. One of the most critical and understudied
                   aspects of diffeomorphic image matching algorithms are its
                   highly ill-conditioned nature. We quantitatively capture the
                   extent of ill-conditioning in a typical MRI matching task,
                   motivating the need for an adaptive optimization algorithm
                   for diffeomorphic matching. To this end, FireANTs generalizes
                   the concept of momentum and adaptive estimates of the Hessian
                   to mitigate this ill-conditioning in the non-Euclidean space
                   of diffeomorphisms. Unlike common non-Euclidean manifolds, we
                   also formalize considerations for multi-scale optimization of
                   diffeomorphisms. Our rigorous mathematical results and
                   operational contributions lead to a state-of-the-art dense
                   matching algorithm that can be applied to generic image data
                   with remarkable accuracy and robustness. We demonstrate
                   consistent improvements in image matching performance across
                   a spectrum of community-standard medical and biological
                   correspondence matching challenges spanning a wide variety of
                   image modalities, anatomies, resolutions, acquisition
                   protocols, and preprocessing pipelines. This improvement is
                   supplemented by from 300x up to 3200x speedup over existing
                   state-of-the-art algorithms. For the first time, we perform
                   diffeomorphic matching of sub-micron mouse cortex volumes at
                   native resolution. Our fast implementation also enables
                   hyperparameter studies that were intractable with existing
                   correspondence matching algorithms.",
  month         =  apr,
  year          =  2024,
  url           = "http://arxiv.org/abs/2404.01249",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "2404.01249"
}

@INPROCEEDINGS{Ntatsis2023-zq,
  title     = "{itk-elastix: Medical image registration in Python}",
  author    = "Ntatsis, Konstantinos and Dekker, Niels and van der Valk, Viktor
               and Birdsong, Tom and Zuki\'{c}, D\v{z}enan and Klein, Stefan and
               Staring, Marius and McCormick, Matthew",
  booktitle = "{Proceedings of the Python in Science Conference}",
  publisher = "SciPy",
  pages     = "101--105",
  abstract  = "Image registration plays a vital role in understanding changes
               that occur in 2D and 3D scientific imaging datasets. In this
               paper, we introduce itk-elastix, a user-friendly Python wrapping
               of the mature elastix registration toolbox.",
  month     =  jun,
  year      =  2023,
  url       = "http://dx.doi.org/10.25080/gerudo-f2bc6f59-00d",
  doi       = "10.25080/gerudo-f2bc6f59-00d",
  issn      = "2575-9752"
}

@ARTICLE{McCormick2014-ok,
  title     = "{ITK: enabling reproducible research and open science}",
  author    = "McCormick, Matthew and Liu, Xiaoxiao and Jomier, Julien and
               Marion, Charles and Ibanez, Luis",
  journal   = "Frontiers in neuroinformatics",
  publisher = "Frontiers Media SA",
  volume    =  8,
  pages     =  13,
  abstract  = "Reproducibility verification is essential to the practice of the
               scientific method. Researchers report their findings, which are
               strengthened as other independent groups in the scientific
               community share similar outcomes. In the many scientific fields
               where software has become a fundamental tool for capturing and
               analyzing data, this requirement of reproducibility implies that
               reliable and comprehensive software platforms and tools should be
               made available to the scientific community. The tools will
               empower them and the public to verify, through practice, the
               reproducibility of observations that are reported in the
               scientific literature. Medical image analysis is one of the
               fields in which the use of computational resources, both software
               and hardware, are an essential platform for performing
               experimental work. In this arena, the introduction of the Insight
               Toolkit (ITK) in 1999 has transformed the field and facilitates
               its progress by accelerating the rate at which algorithmic
               implementations are developed, tested, disseminated and improved.
               By building on the efficiency and quality of open source
               methodologies, ITK has provided the medical image community with
               an effective platform on which to build a daily workflow that
               incorporates the true scientific practices of reproducibility
               verification. This article describes the multiple tools,
               methodologies, and practices that the ITK community has adopted,
               refined, and followed during the past decade, in order to become
               one of the research communities with the most modern
               reproducibility verification infrastructure. For example, 207
               contributors have created over 2400 unit tests that provide over
               84\% code line test coverage. The Insight Journal, an open
               publication journal associated with the toolkit, has seen over
               360,000 publication downloads. The median normalized closeness
               centrality, a measure of knowledge flow, resulting from the
               distributed peer code review system was high, 0.46.",
  month     =  feb,
  year      =  2014,
  url       = "http://dx.doi.org/10.3389/fninf.2014.00013",
  keywords  = "ITK; code review; insight journal; insight toolkit; open science;
               reproducibility",
  doi       = "10.3389/fninf.2014.00013",
  pmc       = "PMC3929840",
  pmid      =  24600387,
  issn      = "1662-5196",
  language  = "en"
}

@ARTICLE{Zuo2014-ub,
  title     = "{An open science resource for establishing reliability and
               reproducibility in functional connectomics}",
  author    = "Zuo, Xi-Nian and Anderson, Jeffrey S and Bellec, Pierre and Birn,
               Rasmus M and Biswal, Bharat B and Blautzik, Janusch and Breitner,
               John C S and Buckner, Randy L and Calhoun, Vince D and
               Castellanos, F Xavier and Chen, Antao and Chen, Bing and Chen,
               Jiangtao and Chen, Xu and Colcombe, Stanley J and Courtney,
               William and Craddock, R Cameron and Di Martino, Adriana and Dong,
               Hao-Ming and Fu, Xiaolan and Gong, Qiyong and Gorgolewski,
               Krzysztof J and Han, Ying and He, Ye and He, Yong and Ho, Erica
               and Holmes, Avram and Hou, Xiao-Hui and Huckins, Jeremy and
               Jiang, Tianzi and Jiang, Yi and Kelley, William and Kelly, Clare
               and King, Margaret and LaConte, Stephen M and Lainhart, Janet E
               and Lei, Xu and Li, Hui-Jie and Li, Kaiming and Li, Kuncheng and
               Lin, Qixiang and Liu, Dongqiang and Liu, Jia and Liu, Xun and
               Liu, Yijun and Lu, Guangming and Lu, Jie and Luna, Beatriz and
               Luo, Jing and Lurie, Daniel and Mao, Ying and Margulies, Daniel S
               and Mayer, Andrew R and Meindl, Thomas and Meyerand, Mary E and
               Nan, Weizhi and Nielsen, Jared A and O'Connor, David and Paulsen,
               David and Prabhakaran, Vivek and Qi, Zhigang and Qiu, Jiang and
               Shao, Chunhong and Shehzad, Zarrar and Tang, Weijun and
               Villringer, Arno and Wang, Huiling and Wang, Kai and Wei, Dongtao
               and Wei, Gao-Xia and Weng, Xu-Chu and Wu, Xuehai and Xu, Ting and
               Yang, Ning and Yang, Zhi and Zang, Yu-Feng and Zhang, Lei and
               Zhang, Qinglin and Zhang, Zhe and Zhang, Zhiqiang and Zhao, Ke
               and Zhen, Zonglei and Zhou, Yuan and Zhu, Xing-Ting and Milham,
               Michael P",
  journal   = "Scientific data",
  publisher = "Springer Science and Business Media LLC",
  volume    =  1,
  number    =  1,
  pages     =  140049,
  abstract  = "Efforts to identify meaningful functional imaging-based
               biomarkers are limited by the ability to reliably characterize
               inter-individual differences in human brain function. Although a
               growing number of connectomics-based measures are reported to
               have moderate to high test-retest reliability, the variability in
               data acquisition, experimental designs, and analytic methods
               precludes the ability to generalize results. The Consortium for
               Reliability and Reproducibility (CoRR) is working to address this
               challenge and establish test-retest reliability as a minimum
               standard for methods development in functional connectomics.
               Specifically, CoRR has aggregated 1,629 typical individuals'
               resting state fMRI (rfMRI) data (5,093 rfMRI scans) from 18
               international sites, and is openly sharing them via the
               International Data-sharing Neuroimaging Initiative (INDI). To
               allow researchers to generate various estimates of reliability
               and reproducibility, a variety of data acquisition procedures and
               experimental designs are included. Similarly, to enable users to
               assess the impact of commonly encountered artifacts (for example,
               motion) on characterizations of inter-individual variation,
               datasets of varying quality are included.",
  month     =  dec,
  year      =  2014,
  url       = "http://dx.doi.org/10.1038/sdata.2014.49",
  doi       = "10.1038/sdata.2014.49",
  pmc       = "PMC4421932",
  pmid      =  25977800,
  issn      = "2052-4463,2052-4463",
  language  = "en"
}

@ARTICLE{Mirhakimi2025-qb,
  title         = "{Numerical uncertainty in linear registration: An
                   experimental study}",
  author        = "Mirhakimi, Niusha and Chatelain, Yohan and Glatard, Tristan
                   and Poline, Jean-Baptiste",
  journal       = "arXiv [q-bio.QM]",
  pages         = "56--66",
  abstract      = "While linear registration is a critical step in MRI
                   preprocessing pipelines, its numerical uncertainty is
                   understudied. Using Monte-Carlo Arithmetic (MCA) simulations,
                   we assessed the most commonly used linear registration tools
                   within major software packages (SPM, FSL, and ANTs) across
                   multiple image similarity measures, two brain templates, and
                   both healthy control (HC, n=50) and Parkinson's Disease (PD,
                   n=50) cohorts. Our findings highlight the influence of linear
                   registration tools and similarity measures on numerical
                   stability. Among the evaluated tools and with default
                   similarity measures, SPM exhibited the highest stability. FSL
                   and ANTs showed greater and similar ranges of variability,
                   with ANTs demonstrating particular sensitivity to numerical
                   perturbations that occasionally led to registration failure.
                   Furthermore, no significant differences were observed between
                   healthy and PD cohorts, suggesting that numerical stability
                   analyses obtained with healthy subjects may generalise to
                   clinical populations. Finally, we also demonstrated how
                   numerical uncertainty measures may support automated quality
                   control (QC) of linear registration results. Overall, our
                   experimental results characterize the numerical stability of
                   linear registration experimentally and can serve as a basis
                   for future uncertainty analyses.",
  month         =  aug,
  year          =  2025,
  url           = "http://dx.doi.org/10.1007/978-3-032-06593-3_6",
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.QM",
  eprint        = "2508.00781",
  doi           = "10.1007/978-3-032-06593-3\_6"
}

@ARTICLE{Ronneberger2015-dn,
  title         = "{U-Net: Convolutional Networks for Biomedical Image
                   Segmentation}",
  author        = "Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas",
  journal       = "arXiv [cs.CV]",
  abstract      = "There is large consent that successful training of deep
                   networks requires many thousand annotated training samples.
                   In this paper, we present a network and training strategy
                   that relies on the strong use of data augmentation to use the
                   available annotated samples more efficiently. The
                   architecture consists of a contracting path to capture
                   context and a symmetric expanding path that enables precise
                   localization. We show that such a network can be trained
                   end-to-end from very few images and outperforms the prior
                   best method (a sliding-window convolutional network) on the
                   ISBI challenge for segmentation of neuronal structures in
                   electron microscopic stacks. Using the same network trained
                   on transmitted light microscopy images (phase contrast and
                   DIC) we won the ISBI cell tracking challenge 2015 in these
                   categories by a large margin. Moreover, the network is fast.
                   Segmentation of a 512x512 image takes less than a second on a
                   recent GPU. The full implementation (based on Caffe) and the
                   trained networks are available at
                   http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
  month         =  may,
  year          =  2015,
  url           = "http://arxiv.org/abs/1505.04597",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "1505.04597",
  doi           = "10.48550/arXiv.1505.04597"
}

@ARTICLE{Zeiler2012-tn,
  title         = "{ADADELTA: An Adaptive Learning Rate Method}",
  author        = "Zeiler, Matthew D",
  journal       = "arXiv [cs.LG]",
  abstract      = "We present a novel per-dimension learning rate method for
                   gradient descent called ADADELTA. The method dynamically
                   adapts over time using only first order information and has
                   minimal computational overhead beyond vanilla stochastic
                   gradient descent. The method requires no manual tuning of a
                   learning rate and appears robust to noisy gradient
                   information, different model architecture choices, various
                   data modalities and selection of hyperparameters. We show
                   promising results compared to other methods on the MNIST
                   digit classification task using a single machine and on a
                   large scale voice dataset in a distributed cluster
                   environment.",
  month         =  dec,
  year          =  2012,
  url           = "http://arxiv.org/abs/1212.5701",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1212.5701",
  doi           = "10.48550/arXiv.1212.5701"
}

@ARTICLE{Deng2012-hh,
  title     = "{The MNIST database of handwritten digit images for machine
               learning research [best of the web]}",
  author    = "Deng, Li",
  journal   = "IEEE Signal Processing Magazine",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  29,
  number    =  6,
  pages     = "141--142",
  abstract  = "In this issue, ``Best of the Web'' presents the modified National
               Institute of Standards and Technology (MNIST) resources,
               consisting of a collection of handwritten digit images used
               extensively in optical character recognition and machine learning
               research.",
  month     =  nov,
  year      =  2012,
  url       = "http://dx.doi.org/10.1109/MSP.2012.2211477",
  doi       = "10.1109/msp.2012.2211477",
  issn      = "1053-5888,1558-0792",
  language  = "en"
}
