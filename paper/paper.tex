% This is a modified version of Springer's LNCS template suitable for anonymized MICCAI 2025 main conference submissions. 
% Original file: samplepaper.tex, a sample chapter demonstrating the LLNCS macro package for Springer Computer Science proceedings; Version 2.21 of 2022/01/12

\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encodings may result in incorrect characters.
%
\usepackage{graphicx,verbatim}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}

\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{cite}
% TODO Remove later
\usepackage[export]{adjustbox} % Add this to your preamble
\usepackage{color,soul}
\newcommand{\TG}[1]{\color{blue}\textsc{From Tristan: }#1\color{black}}
\newcommand{\MD}[1]{\color{magenta}\textsc{From Mathieu: }#1\color{black}}
\newcommand{\HL}[1]{\hl{#1}}
\newcommand{\YC}[1]{\color{green}\textsc{From Yohan: }#1\color{black}}
% End of remove

\begin{document}
%
\title{DynoMP: A Dynamic Mixed Precision Model for Gradient-Based Optimization}
\titlerunning{DynoMP: Dynamic Mixed Precision Optimization}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\begin{comment}  %% Removed for anonymized MICCAI submission
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
	Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
	Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Princeton University, Princeton NJ 08544, USA \and
	Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
	\email{lncs@springer.com}\\
	\url{http://www.springer.com/gp/computer-science/lncs} \and
	ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
	\email{\{abc,lncs\}@uni-heidelberg.de}}

\end{comment}

\author{Anonymized Authors}  %% Added for anonymized MICCAI submission
\authorrunning{Anonymized Author et al.}
\institute{Anonymized Affiliations \\
	\email{email@anonymized.com}}

\maketitle              % typeset the header of the contribution
%
\begin{abstract}
	Gradient-based optimization in medical image analysis is computationally intensive, typically relying on fixed high-precision formats (float64 or float32) despite the potential for acceleration via mixed precision. However, current mixed precision methods often require expensive static analysis or fail to adapt dynamically to specific datasets and pipeline execution phases.
																																																									
	We introduce DynoMP, a Dynamic Mixed Precision optimization approach that estimates and adjusts the minimum required bit-width at runtime to maintain convergence accuracy. We evaluated DynoMP on both the classical ANTs registration pipeline (using the CoRR BMB\_1 dataset) and DL model training, including MNIST, VoxelMorph 2D, and VoxelMorph 3D (using the MNIST and OASIS datasets). Our results demonstrate that DynoMP can significantly reduce precision compared to default float64 or float32 baselines by adapting to the problem at runtime, all while maintaining the accuracy of the baseline method. This dynamic approach offers a promising pathway for achieving resource-efficient and high-performance medical image computing.
																																																																				
	Code is available at \url{https://anonymous.4open.science/r/DynoMP-83F2}.
																																																																				
	\keywords{Mixed Precision \and Image Registration \and Deep Learning.}
																																																																			
\end{abstract}
%
%
%
\section{Introduction}
Gradient-based optimization drives many medical image analysis tasks, from classical image registration to deep learning (DL) model training. However, these processes are computationally demanding---particularly 3D deformable registration, which remains a bottleneck for runtime and memory~\cite{Dugre2025-fs}. As datasets grow and models become more complex, reducing computational costs is critical for clinical scalability.

Mixed precision computing addresses this by strategically combining high- and low-precision arithmetic to reduce resource usage while maintaining accuracy. Since computational complexity scales quadratically with bit-width~\cite{Wang2019-qe}, moving away from standard double (FP64) or single (FP32) precision yields substantial gains. While DL frameworks like PyTorch~\cite{Paszke2019-vk} widely adopt Automatic Mixed Precision (AMP), its application in classical medical imaging remains limited. Instead, current acceleration efforts focus largely on hardware-specific implementations (e.g., FireANTs~\cite{Jena2024-ud}) or DL-based substitutes (e.g., VoxelMorph~\cite{Balakrishnan2019-rx}, FastSurfer~\cite{Henschel2022-wa}). However, these methods are not mutually exclusive with precision optimization; dynamic precision control could benefit both CPU-based pipelines and modern GPU-accelerated models.

Applying reduced precision requires caution. For example, registration is an ill-posed optimization problem where errors can amplify across multi-resolution stages. Recent work~\cite{Mirhakimi2025-qb} shows that numerical uncertainty in ANTs linear registration can induce artifacts comparable to physical head motion (0.2mm). Therefore, precision reduction must be managed carefully to preserve anatomical integrity. Similarly for DL models, if this noise exceeds the gradient signal, optimization can stall or diverge. Standard AMP in PyTorch primarily addresses underflow issues through loss scaling and manages dynamic range but does not dynamically assess whether the mantissa bits are sufficient to represent the update direction accurately. While, existing tools like Verificarlo~\cite{Denis2015-zf,Chatelain2019-vw} enable rigorous precision analysis they incur prohibitive runtime overheads ($2.6\times$ to $16.8\times$)~\cite{Chatelain2019-vw}, making them unsuitable for real-time optimization. Conversely, standard AMP handles underflow via loss scaling but does not dynamically assess if mantissa bits are sufficient to represent gradient updates accurately.

In this work, we introduce DynoMP, a dynamic mixed precision method that adjusts bit-width at runtime based on optimization stability. Unlike fixed heuristics, DynoMP estimates the gradient's signal-to-noise ratio to determine the minimum required precision per optimization step. We evaluate our method on diverse tasks: classical ANTs registration~\cite{Avants2020-xx}, MNIST classification~\cite{Deng2012-hh}, and VoxelMorph registration~\cite{Balakrishnan2019-rx}. We demonstrate that DynoMP maintains baseline accuracy while unlocking the efficiency of lower-precision formats. Our key contributions are: (1) a theoretical framework for estimating minimum precision requirements; (2) a practical dynamic precision control implementation for classical and DL pipelines; and (3) empirical validation demonstrating resource-efficient medical image computing.

\section{Method}
\subsection{Minimum Precision Estimation}
Hayford et al.~\cite{Hayford2024-kb} proposed a theoretical framework linking convergence stability of gradient-based optimization with its data precision $p$, gradient loss $\|\nabla\mathcal{L}(\theta)\|$, Lipschitz constant $K$, and parameter norm $\|\theta\|$. We adapt their Theorem~1 to estimate the minimum precision ($p_{min}$) required to ensure the gradient signal exceeds the noise inherent to a given data format:
\begin{equation}
	p > p_{min} = \log_2 \left( \frac{(4+3\sqrt{2}) K \|\theta\|}{\|\nabla\mathcal{L}(\theta)\|} \right) .
	\label{eq:pmin}
\end{equation}
In practice, computing the Lipschitz constant $K$ is non-trivial, so we empirically estimate it using a finite difference approach:
\begin{equation}
	K \approx \frac{\|\nabla\mathcal{L}(\theta_{t+1}) - \nabla\mathcal{L}(\theta_{t})\|}{\|\theta_{t+1} - \theta_{t}\|} .
\end{equation}
To compute the norm of $\theta$ and $\nabla\mathcal{L}(\theta)$, we flatten their values into a single vector and compute the Euclidean norm. We modified the ITK library and developed a drop-in Python function for PyTorch training to retrieve these metrics at each iterations, compute $p_{min}$, and dynamically adjust the precision of the subsequent iteration accordingly. This method allows us to adapt the precision requirements in real-time, ensuring that we maintain convergence while optimizing computational efficiency.

\subsection{Dynamic Precision Control Policy}
Because hardware and software libraries only support discrete precision formats, the continuous estimate $p_{min}$ must be mapped to a usable bit-width. To prevent excessive casting overhead caused by oscillating precision requirements between iterations, we first apply a moving average filter (window $N=5$) to yield a smoothed estimate $\bar{p}_{min}$. 

We then define a set of available precision formats $\mathcal{P}$ (e.g., corresponding to FP16, BF16, FP32, etc.). At each optimization step, the target precision $p_{target}$ is selected by rounding up to the nearest supported format:
\begin{equation}
    p_{target} = \min \{ p \in \mathcal{P} \mid p \ge \bar{p}_{min} \}
\end{equation}
This policy guarantees that the selected precision always satisfies the theoretical lower bound required for stability, while aggressively downcasting whenever the optimization landscape permits.



\section{Experiments}
\subsection{ANTs registration}
We used the standard ANTs registration~\cite{Avants2008-ea} pipeline (based on ITK~\cite{McCormick2014-ok, Yoo2002-ve}), which performs sequential rigid, affine, and Symmetric Normalization (SyN) stages across four multi-resolution levels. The optimization minimizes Mutual Information (MI) for linear stages and Cross-Correlation (CC) for the deformable SyN stage, iterating until convergence ($10^{-6}$) or a maximum iteration count is reached.

We used the \textit{BMB\_1} site ($N=50$) from the CoRR dataset~\cite{Zuo2014-ub}. We processed the anatomical T1-weighted volumes, performing skull-stripping using the \textit{antsBrainExtraction.sh} script. Brain-extracted volumes were visually quality-controlled against the TemplateFlow tpl-MNI152NLin2009cAsym template.

\subsection{MNIST Classification}
We trained a standard convolutional neural network (CNN) on the MNIST dataset~\cite{Deng2012-hh}, utilizing the architecture defined in the official PyTorch examples\footnote{https://github.com/pytorch/examples/tree/main/mnist}. The network consists of two convolutional layers with max-pooling, followed by two fully connected layers using ReLU activations and dropout. Training was performed for 14 epochs with a batch size of 64, optimized using Adadelta~\cite{Zeiler2012-tn} (learning rate 1.0).

\subsection{VoxelMorph}
VoxelMorph~\cite{Balakrishnan2019-rx} is a UNet~\cite{Ronneberger2015-dn, Isola2016-lu} model for image registration which learns to predict deformation fields between pairs of images. We trained two versions of the model: a 2D version aligning single slices and a 3D version aligning whole volumes. Both models were trained for 100 epochs using the Adam optimizer~\cite{Kingma2014-uf} with a learning rate of $10^{-4}$ and a batch size of 4. The loss function combined mean squared error (MSE) for image similarity and a regularization term to encourage smooth deformations.

We trained the VoxelMorph 2D and 3D models using the Neurite OASIS dataset~\cite{Marcus2007-nm, Hoopes2022-is}, which contains 414 T1-weighted MRI scans. We used the provided affine-aligned volumes and slices (aligned\_norm.nii.gz, slice\_norm.nii.gz), randomly sampling image pairs to learn deformation fields. The data is available at: \url{https://github.com/adalca/medical-datasets/blob/master/neurite-oasis.md}.

\subsection{Mixed Precision Implementation}
Due to an ITK casting bug restricting ANTs to FP64~\cite{Dugre2025-fs}, we employed VPREC to simulate reduced virtual precisions based on our $p_{min}$ estimate. We limit the selection of virtual precisions to FP16, BF16, FP24, FP32, and FP64 for practical relevance. For PyTorch models on H100 GPUs, we dynamically cast the model and data during execution to the nearest supported format (FP16, BF16, FP32). We tracked theoretical FP24 requirements but fell back to FP32 given hardware constraints. TF32 was excluded as its mantissa width matches FP16. We summarize the precision formats and their characteristics in Table~\ref{tab:precisions}.
\begin{table}[h]
	\centering
	\caption{Data Formats Evaluation Summary: X indicates inclusion.}
	\label{tab:precisions}
	\begin{tabular}{lcccccc}
		\hline
		                    & BF16 & FP16 & TF32 & FP24 & FP32 & FP64 \\
		\hline
		\textbf{ITK (ANTs)} & -    & X    & -    & X    & X    & X    \\
		\textbf{PyTorch}    & X    & X    & -    & -    & X    & -    \\
	\end{tabular}
\end{table}

\section{Results}
Figure~\ref{fig:ants-pmin} depicts the estimated $p_{min}$ from our model across iterations. Our results show the required precision for the SyN stage remains below the FP24 threshold, while the rigid and affine stages could leverage FP32 or even FP24 for most iterations (47\%). For the rigid and affine stages, we observe a general increase in required precision across iterations within a resolution level.
\begin{figure*}[htb!]
	\centering
	\includegraphics[width=\textwidth]{figures/pmin_std_bounds.png}
	\caption{ANTs Registration: Estimated $p_{min}$ across iterations for the rigid, affine, and SyN stages at each multi-resolution level. The shaded areas represent the standard deviation across subjects ($N=50$). The horizontal dashed lines indicate the precision thresholds for BF16, FP16 FP24, FP32, and FP64.}
	\label{fig:ants-pmin}
\end{figure*}

We assessed the non-inferiority of our method compared to the FP64 baseline using a one-tailed T-test ($\alpha = 0.05$), testing whether the relative loss difference exceeded a tolerance of $5 \times 10^4$. The test was applied to the final output of each stage, with Bonferroni correction for multiple comparisons. The null hypothesis was not rejected for any stage or level (Table~\ref{tab:ants-ttest}), confirming that DynoMP maintains accuracy comparable to the FP64 baseline. Figure~\ref{fig:ants-loss} depicts the distribution of relative loss differences across stages and levels.
\begin{table}[h]
	\centering
	\caption{Corrected p-values by Registration Stage and Level}
	\begin{tabular}{lcccc}
		\hline
		\textbf{Stage}  & \textbf{Level 0}  & \textbf{Level 1}  & \textbf{Level 2}  & \textbf{Level 3}  \\
		\hline
		\textbf{Rigid}  & 1.00e+00          & 1.89e-01          & 2.25e-01          & \textbf{4.07e-02} \\
		\textbf{Affine} & 1.00e+00          & 1.00e+00          & \textbf{2.26e-03} & \textbf{3.39e-05} \\
		\textbf{SyN}    & \textbf{3.21e-19} & \textbf{2.12e-08} & \textbf{1.80e-05} & \textbf{9.67e-08} \\
		\hline
		\multicolumn{5}{l}{\small \textit{Bold values indicate statistical significance.}}
	\end{tabular}
\end{table}
\begin{figure*}[htb!]
	\centering
	\includegraphics[width=\textwidth]{figures/rel_diff_fp64_dynomp.png}
	\caption{ANTs Registration: Relative accuracy difference between our DynoMP method and the FP64 baseline at the final iteration. Lower values indicate better performance for our method. Individual subject differences are shown, along with the mean and quantiles.}
	\label{fig:ants-loss}
\end{figure*}

Figure~\ref{fig:pytorch-pmin} shows the estimated $p_{min}$ across iterations for the Pytorch models. For MNIST, our model estimate a $p_min$ of FP16 for the early iteration, but it quickly increases to FP32 and remains for the rest of the training. If FP24 hardware were available, it could be leveraged for a majority (64\%) of the training. As with the ANTs registration, we observe a general increase in required precision across iterations of a specific resolution level.

VoxelMorph 2D and 3D models require FP24 precision in the vast majority of iteration; only a limited number ($<10$) of the initial batches require FP16 precision. However, due to the lack of FP24 hardware support on H100 GPUs, we used FP32 instead. BF16 and AMP strategies training diverges after a few batches. Again, we observe a general increase in required precision across iterations, although plateauing after the first 2,000 batches.
\begin{figure*}[htb!]
	\centering
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/mnist_pmin_moving_avg.pdf}
		\caption{MNIST}
		\label{subfig:mnist-pmin}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/vm2d_pmin_moving_avg.pdf}
		\caption{VoxelMorph 2D}
		\label{subfig:vm2d-pmin}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/vm3d_pmin_moving_avg.pdf}
		\caption{VoxelMorph 3D}
		\label{subfig:vm3d-pmin}
	\end{subfigure}
	\caption{Estimated $p_{min}$ across batches for the PyTorch models. The horizontal dashed lines indicate the precision thresholds for BF16, FP16, FP24, and FP32; the color of the data points indicates the data format used at runtime.}
	\label{fig:pytorch-pmin}
\end{figure*}
\begin{figure*}[htb!]
	\centering
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/mnist_loss.pdf}
		\caption{MNIST}
		\label{subfig:mnist-loss}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/vm2d_loss.pdf}
		\caption{VoxelMorph 2D}
		\label{subfig:vm2d-loss}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.32\textwidth}
		\includegraphics[width=\textwidth]{figures/vm3d_loss.pdf}
		\caption{VoxelMorph 3D}
		\label{subfig:vm3d-loss}
	\end{subfigure}
	\caption{Loss Curves for the PyTorch Models batches for the PyTorch models.}
	\label{fig:pytorch-loss}
\end{figure*}

\section{Discussion and Conclusion}
\subsection{Validity of our Theoretical Model}
The theorem from Hayford et al.~\cite{Hayford2024-kb} requires two assumptions: (1) the loss function must be convex, and (2) the gradient of the loss must be K-Lipschitz with $K\le1/\eta$. In practice, verifying these assumptions for complex pipelines is difficult, and for complex optimization problems, the loss convexity assumption is frequently unsatisfied. However, our results demonstrate that we can still leverage this simple model to predict the required minimal precision at each iteration while maintaining acceptable accuracy.

We assess accuracy relative to an FP64 baseline; however, the theoretically optimal precision and output remain unknown. In image registration, there is no absolute ground truth, as multiple valid solutions can exist. Therefore, while FP64 serves as a high-precision reference, it should not be mistaken for a ground truth validation.

\subsection{Implementation Challenges}
Implementing mixed precision in a production environment presents several practical challenges. For example, the current version of the ITK library contains a bug that forces input data to be cast to double precision during interpolation computations. This results in unnecessary overhead, as the system must cast single-precision inputs to double and back during processing. Correcting this is difficult due to the complexity and scale of the existing codebase. Furthermore, extending support to other data formats remains non-trivial. On the hardware side, support for mixed precision is limited on standard CPUs; while specialized hardware exists, the cost is often prohibitive. Finally, the system's robustness is sensitive to data heterogeneity, which can lead to critical failures when input consistency is not maintained.

When simulating different data formats with VPREC, we modified only the precision bits and ignored the exponent range to limit the overhead of calculating the correct range. This decision is supported by our previous results~\cite{Dugre2025-fs}, which showed no significant difference in accuracy when varying the exponent range between 7 and 8 for precisions ranging from 7 to 23 bits.

To prevent excessive casting overhead caused by oscillating precision requirements between iterations, we utilize a rolling average over a window size of five. A stricter approach would require the precision to increase monotonically with the iteration count at each resolution level. However, if a noisy prediction were to occur early on, it would unnecessarily penalize performance for the remainder of the level. In future efforts, we could compare both approaches, as well as test different window sizes.

In summary, this work demonstrates that our theoretical model effectively predicts minimal precision requirements for image registration in ANTs, maintaining accuracy even when strict convexity assumptions are relaxed. We employ a rolling average smoothing strategy to mitigate precision oscillation, avoiding the potential performance penalties of a stricter monotonic approach. However, while the potential for computational efficiency is clear, practical application is currently hindered by a casting bug in the ITK library and limited hardware support for diverse data formats. Future adoption will depend on addressing these infrastructural constraints and validating performance on real hardware, rather than relying on virtual precision simulations.

% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.

\newpage
\bibliographystyle{splncs04}
\bibliography{paper}
\end{document}
